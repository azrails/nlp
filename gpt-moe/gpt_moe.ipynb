{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17ef7ac2-710b-4b82-a8b6-554e636a3142",
   "metadata": {},
   "source": [
    "# Домашнее задание: реализовать GPT-модель с Mixture of Experts слоями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07078c7-3a0e-4e34-9441-ebfbcced5765",
   "metadata": {},
   "source": [
    "## Домашнее задание\n",
    "\n",
    "- Расширьте данный пример, добавив реализацию RMSNorm и rotary embeddings. **(4 балла)**\n",
    "- Проведите эксперимент по изменению числа экспертов и размера модели. **(4 балла)**\n",
    "- Опишите, как scaling laws влияют на производительность модели. **(2 балла)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b480c432-91ce-4205-9cac-679f1d766c25",
   "metadata": {},
   "source": [
    "## Обзор Mixture of Experts (MoE)\n",
    "\n",
    "Mixture of Experts (MoE) – это подход, позволяющий масштабировать модели путём распределения вычислительных задач между несколькими \"экспертами\". Для каждого входа вычисляется распределение вероятностей по экспертам с помощью \"гейтинговой\" сети, и итоговый выход получается как взвешенная сумма выходов экспертов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9499041b-d024-4cd8-814b-0cd33d786521",
   "metadata": {},
   "source": [
    "### Задачи метода MoE:\n",
    "1. Увеличение параметров модели без линейного роста вычислительной нагрузки.\n",
    "2. Обучение специализированных подсетей для различных аспектов данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ecc159-66cb-42a6-891b-e23b0fd0361d",
   "metadata": {},
   "source": [
    "В следующих ячейках представлен упрощённый пример реализации MoE-слоя и его интеграции в трансформер-блок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a859fc84-880f-4dab-ae03-c38dc469e497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58740db2-de6a-4506-b905-4c4510e54dfc",
   "metadata": {},
   "source": [
    "## Реализация MoE-слоя\n",
    "\n",
    "В этой части мы создадим упрощённый класс MoE, где каждый эксперт – это простая линейная трансформация, а гейтинговая сеть определяет веса для каждого эксперта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7fb692c-0dff-4881-9a92-ffe3bbbcfdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример шаблонной реализации MoE (требует доработки)\n",
    "\n",
    "class MixtureOfExperts(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_experts=4):\n",
    "        super(MixtureOfExperts, self).__init__()\n",
    "        self.num_experts = num_experts\n",
    "\n",
    "        # создаь список экспертов (каждый эксперт - линейное преобразование)\n",
    "        self.experts = nn.ModuleList(\n",
    "            [nn.Linear(input_dim, output_dim) for _ in range(num_experts)]\n",
    "        )\n",
    "\n",
    "        # Гейтинговая сеть для определения весов\n",
    "        self.gate = nn.Linear(input_dim, num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # вычислите gate_scores, gate_probs\n",
    "        # примените экспертов к входу x и объедините результаты с использованием весов\n",
    "        # подсказка: используйте torch.stack и torch.sum\n",
    "        # например, gate_scores = self.gate(x)\n",
    "\n",
    "        #[batch_size, input_dim] -> [batch_size, num_experts]\n",
    "        gate_scores = self.gate(x)\n",
    "        gate_probs = F.softmax(gate_scores, dim=-1)\n",
    "\n",
    "        # Применяем каждого эксперта\n",
    "        #[batch_size, output_dim, num_experts]\n",
    "        expert_outputs = torch.stack([expert(x) for expert in self.experts], dim=-1)\n",
    "        # Расширьте размеры gate_probs для совместимости\n",
    "        gate_probs = gate_probs.unsqueeze(2)\n",
    "\n",
    "        # Взвешенная сумма выходов экспертов\n",
    "         #[batch_size, output_dim]\n",
    "        output = torch.sum(expert_outputs * gate_probs, dim=-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b795d6a-89d4-4ff5-ae8f-ee7d0cf41c3e",
   "metadata": {},
   "source": [
    "#### Проверьте работу MoE-слоя на тестовом входе (при необходимости)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf45e9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def test_moe_out():\n",
    "    moe = MixtureOfExperts(10, 15, num_experts=4)\n",
    "    moe.gate.weight.data.fill_(1.0)\n",
    "    moe.gate.bias.data.fill_(0.0)\n",
    "    for expert in moe.experts:\n",
    "        expert.weight.data.fill_(1.0)\n",
    "        expert.bias.data.fill_(0.0)\n",
    "    x = torch.ones(2, 2, 10)\n",
    "    out = moe(x)\n",
    "    assert out.shape == (2, 2, 15), \"Output shape mismatch\"\n",
    "    assert torch.allclose(out, 10 * torch.ones((2, 2, 15))), \"Wrong output\"\n",
    "test_moe_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db10ae7-aac6-4d4e-9358-ca187efcb712",
   "metadata": {},
   "source": [
    "## Объяснение реализации MoE-слоя\n",
    "\n",
    "- **self.experts:** Список линейных слоёв, каждый из которых является \"экспертом\".\n",
    "- **self.gate:** Линейный слой, выдающий веса для каждого эксперта.\n",
    "- **forward:** Вычисляется softmax по выходу гейта, затем каждое линейное преобразование применяется к входу и комбинируется с помощью весов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ded4d448-a99f-4c91-bbd6-fd717977e1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# класс TransformerBlockMoE (требует доработки)\n",
    "\n",
    "class TransformerBlockMoE(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_experts=4, is_causal=True):\n",
    "        super(TransformerBlockMoE, self).__init__()\n",
    "        # многоголовое внимание\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            embed_dim=d_model, num_heads=num_heads, batch_first=True\n",
    "        )\n",
    "        self.head_size = d_model // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.qkv_projection = nn.Linear(d_model, 3 * d_model)\n",
    "        # слои нормализации\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        # MoE слой вместо стандартного feed-forward слоя\n",
    "        self.moe = MixtureOfExperts(d_model, d_ff, num_experts=num_experts)\n",
    "        # приводим к исходной размерности\n",
    "        self.fc = nn.Linear(d_ff, d_model)\n",
    "        self.is_causal=is_causal\n",
    "\n",
    "    def forward(self, x, attention_mask = None):\n",
    "        if self.is_causal:\n",
    "            attention_mask = torch.ones((x.size(0) * self.num_heads, x.size(1), x.size(1)))\n",
    "            attention_mask = torch.triu(attention_mask, diagonal=1).bool()\n",
    "        #[bc, seq_len, d_model] -> [bc, seq_len, head_size * num_heads * 3]\n",
    "        q,k,v = self.qkv_projection(x).chunk(3, dim=-1)\n",
    "        attn_output, _ = self.attn(\n",
    "            q, k, v,\n",
    "            attn_mask = attention_mask,\n",
    "            is_causal = self.is_causal\n",
    "            )\n",
    "        x = self.norm1(x + attn_output)\n",
    "\n",
    "        # шаг 2: Применение MoE слоя с активацией ReLU\n",
    "        moe_output = self.moe(x)\n",
    "        ff_output = self.fc(F.relu(moe_output))\n",
    "        x = self.norm2(x + ff_output)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f321d048-c555-4237-9920-92371997b4bb",
   "metadata": {},
   "source": [
    "## Объяснение трансформер-блока с MoE\n",
    "\n",
    "- **Многоголовое внимание:** Стандартное self-attention.\n",
    "- **norm1 и norm2:** Слои нормализации для стабилизации обучения.\n",
    "- **MoE-слой:** Заменяет обычный feed-forward слой.\n",
    "- **fc:** Линейное преобразование для приведения размерности обратно к d_model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cfb810-c311-430d-bf3b-1bb2a896519c",
   "metadata": {},
   "source": [
    "## Тестирование трансформер-блока с MoE\n",
    "\n",
    "В следующей ячейке создадим тестовый пример:\n",
    "- Сгенерируем случайный вход (например, эмбеддинги токенов)\n",
    "- Пропустим вход через блок и выведем форму выходного тензора.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "846f2723-3598-49aa-aed5-55aa946237bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма входного тензора: torch.Size([2, 10, 32])\n",
      "Форма выходного тензора: torch.Size([2, 10, 32])\n"
     ]
    }
   ],
   "source": [
    "# Тестовый пример использования TransformerBlockMoE\n",
    "\n",
    "# Задайте параметры модели\n",
    "batch_size = 2\n",
    "seq_len = 10\n",
    "d_model = 32\n",
    "num_heads = 4\n",
    "d_ff = 64\n",
    "\n",
    "# Сгенерируйте случайный вход\n",
    "x = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "# Инициализируйте блок трансформера с MoE\n",
    "transformer_block = TransformerBlockMoE(d_model, num_heads, d_ff, num_experts=4)\n",
    "\n",
    "# Пропустите вход через блок\n",
    "output = transformer_block(x)\n",
    "\n",
    "# Выведите формы входного и выходного тензоров\n",
    "print(\"Форма входного тензора:\", x.shape)\n",
    "print(\"Форма выходного тензора:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdaee4e-10ed-4ca3-894d-b61038b7ef5d",
   "metadata": {},
   "source": [
    "## Дополнительные темы для изучения\n",
    "\n",
    "- **RMSNorm:** Альтернатива стандартной нормализации для улучшения обучения.\n",
    "- **Rotary embeddings:** Улучшают представление позиционной информации.\n",
    "- **Grouped Query Attention:** Модификация механизма внимания для повышения эффективности.\n",
    "\n",
    "*Попробуйте самостоятельно интегрировать эти элементы в модель.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9e3ae68-a77b-4f50-afea-92d28e1ae830",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, d_model:int, eps:float=1e-8, elementwise_affine:bool=True):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.gamma = nn.Parameter(\n",
    "            torch.ones(d_model),\n",
    "            requires_grad=True if elementwise_affine else None\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #faster than .pow\n",
    "        sqare = x * x\n",
    "        denominator = (sqare.sum(dim=-1, keepdim=True) / x.size(dim=-1) + self.eps).pow(0.5)\n",
    "        return x / denominator * self.gamma\n",
    "\n",
    "@torch.no_grad\n",
    "def test_rms_out():\n",
    "    norm = RMSNorm(10)\n",
    "    inp = torch.ones((2, 2, 10))\n",
    "    out = norm(inp)\n",
    "    assert out.shape == inp.shape, \"Wrong shape impl\"\n",
    "    assert torch.allclose(out, inp), \"Wrong numerical impl\"\n",
    "test_rms_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad363652",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoPE(nn.Module):\n",
    "    def __init__(self, d_model:int, max_len:int, base:int=100_000):\n",
    "        super().__init__()\n",
    "        assert d_model % 2 == 0, \"Embedding size must be divisible by 2\"\n",
    "        self.register_buffer(\n",
    "            \"bias\", self._build_bias(d_model, max_len, base), persistent=False\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Make rope rotation in complex space for simplicity\n",
    "        \"\"\"\n",
    "        #x.shape -> [bc, seq, head_size]\n",
    "        orig_dtype = x.dtype\n",
    "        orig_shape = x.shape\n",
    "\n",
    "        #[bc, seq, head_size//2, 2]\n",
    "        x = x.view(*orig_shape[:2], -1, 2).contiguous()\n",
    "        x = torch.view_as_complex(x)\n",
    "        x = self.bias[:orig_shape[1]] * x\n",
    "        x = torch.view_as_real(x)\n",
    "        x = x.view(orig_shape)\n",
    "        return x.to(orig_dtype)\n",
    "\n",
    "    def _build_bias(self, d_model, max_len, base):\n",
    "        seq_idx = torch.arange(0, max_len)\n",
    "        theta = 1.0 / base ** (torch.arange(0, d_model, 2) / d_model)\n",
    "        position_matrix = torch.outer(seq_idx, theta)\n",
    "        bias = torch.polar(torch.ones_like(position_matrix), position_matrix)\n",
    "        return bias\n",
    "\n",
    "@torch.no_grad\n",
    "def test_rope_out():\n",
    "    rope = RoPE(10, 4)\n",
    "    inp = torch.ones((2, 4, 10))\n",
    "    out = rope(inp)\n",
    "    assert out.shape == inp.shape, \"Wrong shape impl\"\n",
    "    assert torch.allclose(out[0, 0], torch.ones((10)))\n",
    "test_rope_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0d97d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GQAsdpa(nn.Module):\n",
    "    def __init__(\n",
    "            self, d_model:int, num_q_heads:int,\n",
    "            num_kv_heads:int, drop_p:float=.0, bias:bool=False, norm=None\n",
    "            ):\n",
    "        super().__init__()\n",
    "        assert num_q_heads % num_kv_heads == 0, \"Num q heads must be divisible by kv heads\"\n",
    "        assert d_model % num_q_heads == 0, \"Model size must be divisible by num heads\"\n",
    "        self.head_size = d_model // num_q_heads\n",
    "        self.num_q_heads = num_q_heads\n",
    "        self.num_kv_heads = num_kv_heads\n",
    "        self.group_size = num_q_heads // num_kv_heads\n",
    "        self.norm = torch.sqrt(\n",
    "            torch.tensor(self.head_size)) if norm is None else norm\n",
    "        self.kv_proj = nn.Linear(\n",
    "            d_model, 2 * self.head_size * num_kv_heads, bias=bias\n",
    "            )\n",
    "        self.q_proj = nn.Linear(\n",
    "            d_model, self.head_size * num_q_heads, bias=bias\n",
    "            )\n",
    "        self.out_proj = nn.Linear(\n",
    "            d_model, d_model, bias=bias\n",
    "            )\n",
    "        self.act = nn.Softmax(dim=-1)\n",
    "        self.dropout = nn.Dropout(drop_p)\n",
    "\n",
    "    def forward(self, x, attention_mask = None, is_causal=True):\n",
    "        if attention_mask is not None:\n",
    "            attention_mask = torch.where(\n",
    "                attention_mask == 1, 1, torch.finfo(x.dtype).min\n",
    "                )\n",
    "        if is_causal:\n",
    "            causal_mask = torch.full(\n",
    "                (x.size(0), self.num_kv_heads, self.group_size, x.size(1), x.size(1)),\n",
    "                fill_value=torch.finfo(x.dtype).min\n",
    "                )\n",
    "            causal_mask = torch.triu(causal_mask, diagonal=1)\n",
    "            attention_mask = causal_mask if attention_mask is None else (attention_mask * causal_mask)\n",
    "\n",
    "        #[bc, seq, num_kv_heads, 1, head_size]\n",
    "        k,v = self.kv_proj(x).reshape(*x.shape[:2], self.num_kv_heads, 1, 2 * self.head_size).chunk(2, dim=-1)\n",
    "\n",
    "        #[bc, seq, num_kv_heads, heads_per_group, head_size]\n",
    "        q = self.q_proj(x).reshape(*x.shape[:2], self.num_kv_heads, -1, self.head_size)\n",
    "\n",
    "        #[bc, num_groups, group_size, head_size, seq]\n",
    "        q = q.permute(0, 2, 3, 1, 4).contiguous()\n",
    "        #[bc, num_groups, group_size, seq, head_size]\n",
    "        k = k.permute(0, 2, 3, 4, 1).contiguous()\n",
    "        v = v.permute(0, 2, 3, 1, 4).contiguous()\n",
    "        #[bc, num_groups, heads_per_group, seq, seq]\n",
    "        attn_weight = q @ k + attention_mask\n",
    "        #[bc, num_groups, heads_per_group, seq, head_size]\n",
    "        out = self.act(self.dropout(attn_weight / self.norm)) @ v\n",
    "        out = out.permute(0, 3, 1, 2, 4).reshape(*x.shape[:2], -1)\n",
    "        out = self.out_proj(out)\n",
    "        return out, attn_weight\n",
    "\n",
    "@torch.no_grad\n",
    "def test_gqa_out():\n",
    "    attn_fn = GQAsdpa(16, 8, 2)\n",
    "    x = torch.ones((2, 5, 16))\n",
    "    out, _ = attn_fn(x)\n",
    "    assert x.shape == out.shape\n",
    "test_gqa_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb595279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма входного тензора: torch.Size([2, 10, 32])\n",
      "Форма выходного тензора: torch.Size([2, 10, 32])\n"
     ]
    }
   ],
   "source": [
    "class TransformerBlockGQA(nn.Module):\n",
    "    def __init__(\n",
    "            self, d_model, d_ff, num_q_heads, num_kv_heads, num_experts=4, is_causal=True\n",
    "            ):\n",
    "        super().__init__()\n",
    "        # многоголовое внимание\n",
    "        self.attn = GQAsdpa(\n",
    "            d_model, num_q_heads, num_kv_heads\n",
    "        )\n",
    "        self.head_size = d_model // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        # слои нормализации\n",
    "        self.norm1 = RMSNorm(d_model)\n",
    "        self.norm2 = RMSNorm(d_model)\n",
    "        # MoE слой вместо стандартного feed-forward слоя\n",
    "        self.moe = MixtureOfExperts(d_model, d_ff, num_experts=num_experts)\n",
    "        # приводим к исходной размерности\n",
    "        self.fc = nn.Linear(d_ff, d_model)\n",
    "        self.is_causal = is_causal\n",
    "\n",
    "    def forward(self, x, attention_mask = None):\n",
    "        # шаг 1: Многоголовое внимание\n",
    "        #[bc, seq_len, d_model] -> [bc, seq_len, head_size * num_heads * 3]\n",
    "        attn_output, _ = self.attn(x, attention_mask, self.is_causal)\n",
    "        x = self.norm1(x + attn_output)\n",
    "\n",
    "        # шаг 2: Применение MoE слоя с активацией ReLU\n",
    "        moe_output = self.moe(x)\n",
    "        ff_output = self.fc(F.relu(moe_output))\n",
    "        x = self.norm2(x + ff_output)\n",
    "        return x\n",
    "\n",
    "@torch.no_grad\n",
    "def test_block_gqu_out():\n",
    "    batch_size = 2\n",
    "    seq_len = 10\n",
    "    d_model = 32\n",
    "    num_q_heads = 8\n",
    "    num_kv_heads = 2\n",
    "    d_ff = 64\n",
    "\n",
    "    # Сгенерируйте случайный вход\n",
    "    x = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "    # Инициализируйте блок трансформера с MoE\n",
    "    transformer_block = TransformerBlockGQA(d_model, d_ff, num_q_heads, num_kv_heads, num_experts=4)\n",
    "\n",
    "    # Пропустите вход через блок\n",
    "    output = transformer_block(x)\n",
    "\n",
    "    # Выведите формы входного и выходного тензоров\n",
    "    print(\"Форма входного тензора:\", x.shape)\n",
    "    print(\"Форма выходного тензора:\", output.shape)\n",
    "\n",
    "test_block_gqu_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9074c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TransformerConfig:\n",
    "    num_layers: int = 8\n",
    "    vocab_size: int = 1024\n",
    "    d_model: int = 256\n",
    "    d_ff: int = 1024\n",
    "    use_gqa: bool = True\n",
    "    num_heads: int = 9\n",
    "    num_q_heads: int = 9\n",
    "    num_kv_heads: int = 3\n",
    "    num_experts: int = 4\n",
    "    tie_embeddings: bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fd5a4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма входного тензора: torch.Size([2, 25])\n",
      "Форма выходного тензора: torch.Size([2, 25, 1024])\n",
      "Форма выходного тензора gqa: torch.Size([2, 25, 1024])\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, cfg: TransformerConfig):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(cfg.vocab_size, cfg.d_model)\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerBlockGQA(cfg.d_model, cfg.d_ff, cfg.num_q_heads, cfg.num_kv_heads, cfg.num_experts)\n",
    "            if cfg.use_gqa else TransformerBlockMoE(cfg.d_model, cfg.num_heads, cfg.d_ff, cfg.num_experts)\n",
    "            for _ in range(cfg.num_layers)\n",
    "        ])\n",
    "        self.lm_head = nn.Linear(cfg.d_ff, cfg.vocab_size, bias=False)\n",
    "        if cfg.tie_embeddings:\n",
    "            self.lm_head.weight = self.embedding.weight\n",
    "        \n",
    "    def forward(self, x, attention_mask=None):\n",
    "        out = self.embedding(x)\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, attention_mask)\n",
    "        out = self.lm_head(out)\n",
    "        return out\n",
    "\n",
    "@torch.no_grad\n",
    "def test_block_gqu_out():\n",
    "    config_gqa = TransformerConfig(\n",
    "        num_layers=2,\n",
    "        vocab_size=1024,\n",
    "        d_model=36,\n",
    "        d_ff=1024,\n",
    "    )\n",
    "    config = TransformerConfig(\n",
    "        num_layers=2,\n",
    "        vocab_size=1024,\n",
    "        d_model=36,\n",
    "        d_ff=1024,\n",
    "        use_gqa=False\n",
    "    )\n",
    "\n",
    "    # Инициализируйте блок трансформера с MoE\n",
    "    transformer = Decoder(config)\n",
    "    transformer_gqa = Decoder(config_gqa)\n",
    "    x = torch.arange(1, 26).long().expand(2, -1)\n",
    "    out = transformer(x)\n",
    "    out_gqa = transformer_gqa(x)\n",
    "    # Выведите формы входного и выходного тензоров\n",
    "    print(\"Форма входного тензора:\", x.shape)\n",
    "    print(\"Форма выходного тензора:\", out.shape)\n",
    "    print(\"Форма выходного тензора gqa:\", out_gqa.shape)\n",
    "    assert out.shape == (2, 25, 1024)\n",
    "    assert out_gqa.shape == (2, 25, 1024)\n",
    "\n",
    "test_block_gqu_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fdc2de",
   "metadata": {},
   "source": [
    "### Изменение числа параметров модели при изменении конфигурации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a97a19e",
   "metadata": {},
   "source": [
    "#### Изменение числа параметров с ростом числа блоков\n",
    "\n",
    "Без GQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53a0f04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_layers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.925508</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_layers: \u001b[1;36m1\u001b[0m params: \u001b[1;36m11.925508\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m1.0\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_layers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56.807448</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.763524371456545</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_layers: \u001b[1;36m6\u001b[0m params: \u001b[1;36m56.807448\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m4.763524371456545\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_layers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101.689388</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.52704874291309</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_layers: \u001b[1;36m11\u001b[0m params: \u001b[1;36m101.689388\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m8.52704874291309\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_layers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146.571328</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12.290573114369634</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_layers: \u001b[1;36m16\u001b[0m params: \u001b[1;36m146.571328\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m12.290573114369634\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_layers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">191.453268</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.05409748582618</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_layers: \u001b[1;36m21\u001b[0m params: \u001b[1;36m191.453268\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m16.05409748582618\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_layers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">236.335208</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19.817621857282724</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_layers: \u001b[1;36m26\u001b[0m params: \u001b[1;36m236.335208\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m19.817621857282724\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_layers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">281.217148</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23.58114622873927</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_layers: \u001b[1;36m31\u001b[0m params: \u001b[1;36m281.217148\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m23.58114622873927\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_layers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">326.099088</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27.344670600195812</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_layers: \u001b[1;36m36\u001b[0m params: \u001b[1;36m326.099088\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m27.344670600195812\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_layers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">370.981028</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31.108194971652356</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_layers: \u001b[1;36m41\u001b[0m params: \u001b[1;36m370.981028\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m31.108194971652356\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_layers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">415.862968</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34.87171934310891</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_layers: \u001b[1;36m46\u001b[0m params: \u001b[1;36m415.862968\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m34.87171934310891\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print\n",
    "model_config = TransformerConfig(\n",
    "        num_layers=10,\n",
    "        vocab_size=1024,\n",
    "        d_model=576,\n",
    "        d_ff=2304,\n",
    "        use_gqa=False,\n",
    "        num_heads=9,\n",
    "        num_q_heads=9,\n",
    "        num_kv_heads=3,\n",
    "        num_experts=4,\n",
    "        tie_embeddings=False\n",
    "    )\n",
    "\n",
    "def change_num_layers(base_config):\n",
    "    min_params = 1\n",
    "    for i in range(1, 50, 5):\n",
    "        base_config.num_layers = i\n",
    "        model = Decoder(base_config)\n",
    "        num_params = sum(p.numel() for p in model.parameters()) / 1e6\n",
    "        if i == 1:\n",
    "            min_params = num_params    \n",
    "        print(f\"d_model: {base_config.d_model}, num_layers: {i} params: {num_params} М\\n\" +\n",
    "              f\"Прирост числа параметров: {num_params / min_params}%\")\n",
    "change_num_layers(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fbae8e",
   "metadata": {},
   "source": [
    "С GQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84c3756c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_layers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.482628</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_layers: \u001b[1;36m1\u001b[0m params: \u001b[1;36m10.482628\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m1.0\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_layers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.150168</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.593329840570513</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_layers: \u001b[1;36m6\u001b[0m params: \u001b[1;36m48.150168\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m4.593329840570513\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_layers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">85.817708</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.186659681141027</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_layers: \u001b[1;36m11\u001b[0m params: \u001b[1;36m85.817708\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m8.186659681141027\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_layers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">123.485248</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.77998952171154</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_layers: \u001b[1;36m16\u001b[0m params: \u001b[1;36m123.485248\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m11.77998952171154\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_layers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">161.152788</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15.373319362282052</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_layers: \u001b[1;36m21\u001b[0m params: \u001b[1;36m161.152788\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m15.373319362282052\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_layers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">198.820328</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.966649202852565</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_layers: \u001b[1;36m26\u001b[0m params: \u001b[1;36m198.820328\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m18.966649202852565\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_layers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">236.487868</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22.55997904342308</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_layers: \u001b[1;36m31\u001b[0m params: \u001b[1;36m236.487868\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m22.55997904342308\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_layers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">274.155408</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26.153308883993596</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_layers: \u001b[1;36m36\u001b[0m params: \u001b[1;36m274.155408\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m26.153308883993596\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_layers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">311.822948</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29.746638724564107</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_layers: \u001b[1;36m41\u001b[0m params: \u001b[1;36m311.822948\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m29.746638724564107\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_layers: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">349.490488</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33.339968565134626</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_layers: \u001b[1;36m46\u001b[0m params: \u001b[1;36m349.490488\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m33.339968565134626\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_config = TransformerConfig(\n",
    "        num_layers=10,\n",
    "        vocab_size=1024,\n",
    "        d_model=576,\n",
    "        d_ff=2304,\n",
    "        use_gqa=True,\n",
    "        num_heads=9,\n",
    "        num_q_heads=9,\n",
    "        num_kv_heads=3,\n",
    "        num_experts=4,\n",
    "        tie_embeddings=False\n",
    "    )\n",
    "\n",
    "def change_num_layers(base_config):\n",
    "    min_params = 1\n",
    "    for i in range(1, 50, 5):\n",
    "        base_config.num_layers = i\n",
    "        model = Decoder(base_config)\n",
    "        num_params = sum(p.numel() for p in model.parameters()) / 1e6\n",
    "        if i == 1:\n",
    "            min_params = num_params    \n",
    "        print(f\"d_model: {base_config.d_model}, num_layers: {i} params: {num_params} М\\n\" +\n",
    "              f\"Прирост числа параметров: {num_params / min_params}%\")\n",
    "change_num_layers(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8948ea",
   "metadata": {},
   "source": [
    "#### Изменение числа параметров с ростом числа экспертов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3652ca28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_experts: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">52.81345</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_experts: \u001b[1;36m1\u001b[0m params: \u001b[1;36m52.81345\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m1.0\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_experts: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">119.3127</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.2591347469252625</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_experts: \u001b[1;36m6\u001b[0m params: \u001b[1;36m119.3127\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m2.2591347469252625\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_experts: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">185.81195</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.5182694938505246</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_experts: \u001b[1;36m11\u001b[0m params: \u001b[1;36m185.81195\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m3.5182694938505246\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_experts: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">252.3112</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.7774042407757875</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_experts: \u001b[1;36m16\u001b[0m params: \u001b[1;36m252.3112\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m4.7774042407757875\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_experts: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">318.81045</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.036538987701049</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_experts: \u001b[1;36m21\u001b[0m params: \u001b[1;36m318.81045\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m6.036538987701049\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_experts: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">385.3097</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.295673734626312</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_experts: \u001b[1;36m26\u001b[0m params: \u001b[1;36m385.3097\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m7.295673734626312\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_experts: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">451.80895</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.554808481551573</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_experts: \u001b[1;36m31\u001b[0m params: \u001b[1;36m451.80895\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m8.554808481551573\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d_model: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, num_experts: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span> params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">518.3082</span> М\n",
       "Прирост числа параметров: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.813943228476838</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d_model: \u001b[1;36m576\u001b[0m, num_experts: \u001b[1;36m36\u001b[0m params: \u001b[1;36m518.3082\u001b[0m М\n",
       "Прирост числа параметров: \u001b[1;36m9.813943228476838\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_config = TransformerConfig(\n",
    "        num_layers=10,\n",
    "        vocab_size=1024,\n",
    "        d_model=576,\n",
    "        d_ff=2304,\n",
    "        use_gqa=False,\n",
    "        num_heads=12,\n",
    "        num_q_heads=9,\n",
    "        num_kv_heads=3,\n",
    "        num_experts=4,\n",
    "        tie_embeddings=False\n",
    "    )\n",
    "def change_num_experts(base_config):\n",
    "    min_params = 1\n",
    "    for i in range(1, 40, 5):\n",
    "        base_config.num_experts = i\n",
    "        model = Decoder(base_config)\n",
    "        num_params = sum(p.numel() for p in model.parameters()) / 1e6\n",
    "        if i == 1:\n",
    "            min_params = num_params    \n",
    "        print(f\"d_model: {base_config.d_model}, num_experts: {i} params: {num_params} М\\n\" +\n",
    "              f\"Прирост числа параметров: {num_params / min_params}%\")\n",
    "change_num_experts(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c83f1a",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2321d3fb",
   "metadata": {},
   "source": [
    "Из полученных данных можно сделать вывод, что использование большего числа экспертов значительно увеличивает размер модели в ширину, при этом сохраняя ту же вычислительную сложность (подразумевается реализация moe, через top k) что и у базовой модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6589335d",
   "metadata": {},
   "source": [
    "С другой же стороны при росте числа блоков увеличивается вычислительная сложность модели с увеличением числа параметров, так же можно заметить что использование GQA значительно снижает вычислительную сложность модели."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
